Title: The Bullshit Compass: Trying to Measure the Unmeasurable (Semantic Pattern Detection Framework v0.88 - Emphasizing Graeber & Cultural Nuance)

Request for Comments: RFC FS02
(Replaces: v0.2.2)
Category: Experimental / Informational / Epistemologically & Sociologically Curious
Author: Rob Tyrie, Ironstone Advisory & Finger Spider Project (Still trying!)
Date: April 1, 2025 (This date is becoming a running gag)
Notes and comment  to rob@ironstoneadvisory.com or http://wwwlinkedin.com/in/robtyrie

Title: The Bullshit Compass: Trying to Measure the Unmeasurable (Semantic Pattern Detection Framework v0.2.3 - Emphasizing Graeber & Cultural Nuance)
https://github.com/Ironstone-Advisory/BullshitCompass/tree/main
(RFC format persists. We're building on the shoulders of giants... or at least standing near them.)
Status of this Memo
Version 0.88! Refining the blend. This iteration specifically revisits and emphasizes the potential link between the nature of work and bullshit production (hello again, David Graeber) and the fascinating, thorny issue of how bullshit might look different across languages and cultures. We're trying to be clear about what the Compass does versus the broader context it operates in. Keep the feedback coming!
Abstract
We navigate a world dense with language crafted for effect rather than accuracy – Frankfurt's (1986) "bullshit." The Bullshit Compass is a proposed system to detect this indifference to truth in text, using linguistics, philosophy (Frankfurt, Grice, Orwell...), psychology (Kahneman, Ariely), and AI. This version re-emphasizes the potential sociological context suggested by Graeber's (2018) "Bullshit Jobs" theory – that certain work structures might incentivize bullshit language – while clarifying the Compass analyzes text, not jobs. It also reiterates the ambition and challenge of exploring cross-cultural linguistic markers for bullshit. The goal remains a tool for clarity and critical thinking (Parrish).

Table of Contents
Introduction: Why So Much Bullshit? (Revisiting Graeber's Context)
Terminology: Defining Our Demons (Incl. Bullshit Jobs/Objects)
The Bullshit Compass: Design, Philosophy & The Specter of Bullshit Jobs
Core Indicators: The Patterns We Look For (Text-Based Only!)
4.1. TCR / 4.2. PWI / 4.3. SDS / 4.4. AAR / 4.5. BLI / 4.6. PRM / 4.7. EPF / 4.8. OOI
Context: Wittgenstein, Grice, Genre, and Culture
5.1. Language Game Contextualization (LGC)
AI vs. AI: The LLM Conundrum
Outputs: What You Get From the Machine
7.1. Potential Readouts
7.2. Potential Users
Implementation: How It's (Supposedly) Built
8.1. Current Status
8.2. Integration Dreams
8.3. Open Source Plan
Future Work: Where We Go From Here (Incl. Cross-Cultural Deep Dive)
9.1. Quantitative Bullshit Module?
9.2. Refining Indicators
9.3. Beyond English: The Cross-Cultural Bullshit Challenge (Emphasized)
Caveats Emptor: How Not To Wield This Thing
The Big Why: Motivation Recap
Speak Now: Request for Comments
Bibliography: The Thinkers Behind the Madness
Contact Point
Legal Disclaimers
1. Introduction: Why So Much Bullshit? (Revisiting Graeber's Context)
The modern info-sphere often feels like wading through linguistic sludge. Frankfurt (1986) gave us the term "bullshit" for language unconcerned with truth. But why is it seemingly everywhere, especially in professional settings?
One compelling, if unsettling, perspective comes from David Graeber's (2018) work on "Bullshit Jobs." He argued that many modern jobs are fundamentally pointless, leading employees to engage in performative work. Our hypothesis, building on Graeber, is that such roles might necessitate the creation of "bullshit knowledge objects" – texts that exist primarily to signal activity or justify a role, rather than convey substantive meaning. If your job feels pointless, generating elaborate but empty reports might become a survival strategy.
Let's be crystal clear: The Bullshit Compass is a text analysis tool. It CANNOT and SHOULD NOT be used to assess whether an author has a "bullshit job." That's ethically fraught and practically impossible from text alone. However, Graeber's theory provides crucial background context. It suggests systemic, economic pressures might drive the production of bullshit language in certain sectors. This makes text-based detection tools potentially more valuable, as they focus on the output, not speculative judgments about the author's situation.
(Rest of intro follows previous versions: risks, inadequacy of current tools, etc.)
2. Terminology: Defining Our Demons (Incl. Bullshit Jobs/Objects)
(Largely same as v0.2.2. Ensure these are present:)
Bullshit (Frankfurt): Indifference to truth.
Bullshit Jobs (Graeber): Pointless jobs potentially requiring performative work. (Contextual term).
Bullshit Knowledge Object: Our term for text artifacts potentially resulting from such performative work. (Hypothetical construct).
(Plus: Semantic Pattern Detection, Epistemic Quality, Language Game, Orwellian Language, Gricean Maxims, System 1/2, Critical Discourse Analysis)
3. The Bullshit Compass: Design, Philosophy & The Specter of Bullshit Jobs
(Architecture: RFC spec, philosophy, NLP/ML. Cognitive tool goal (Parrish, Kahneman)). Add this clarification:
While the Compass analyzes linguistic patterns in text, its raison d'être is partly informed by observing contexts where bullshit seems prevalent. Theories like Graeber's, suggesting structural reasons for bullshit production, underscore the need for objective, text-focused analysis tools. The Compass aims to evaluate the textual artifact (the potential "bullshit knowledge object") on its own merits, independent of assumptions about its creator's role or motivations.
4. Core Indicators: The Patterns We Look For (Text-Based Only!)
(Definitions refined for clarity, consistent with previous versions but presented with more confidence)
Bullshit (Frankfurt): Language used with indifference to truth or accuracy.
Epistemic Quality: The degree to which language appears oriented towards truth, evidence, and clarity. The Compass seeks markers of low epistemic quality.
Semantic Pattern Detection: Analyzing text for recurring meaning-based structures indicative of specific rhetorical strategies or epistemic stances.
Language Game (Wittgenstein): The contextual rules governing language use in a specific activity (report, satire, marketing). Crucial for the LGC module.
Gricean Maxims: Cooperative principles (Quality, Quantity, Relation, Manner) often violated by bullshit.
Orwellian Language: Obfuscatory, vague, or euphemistic language hindering clear thought (cf. Orwell, Snyder).
System 1 / System 2 (Kahneman): Bullshit often targets fast, intuitive System 1; the Compass aims to engage slower, analytical System 2.
Bullshit Jobs / Knowledge Objects (Graeber Context): Sociological concepts providing background on potential drivers for bullshit production; not directly 
5. Context: Wittgenstein, Grice, Genre, and Culture
(LGC description remains focused on genre/activity context per Wittgenstein/Grice. Acknowledge again that cultural context adds another layer, detailed in 9.3).
6. AI vs. AI: The LLM Conundrum

7. Outputs: What You Get From the Machine
(Content unchanged: Score, Radar Chart, Annotations, Rewrite Suggestions).
8. Implementation: How It's (Supposedly) Built
(Content unchanged: Python, CLI, planned integrations, MIT license).
9. Future Work: Where We Go From Here (Incl. Cross-Cultural Deep Dive)
(Keep previous plans: Quant BS module, Indicator refinement).
9.3. Beyond English: The Cross-Cultural Bullshit Challenge (Emphasized)
This is a major, long-term ambition requiring significant research and collaboration.
Universality & Variation: While the core phenomenon of bullshit (indifference to truth) seems depressingly cross-cultural, its linguistic expression likely varies significantly. What sounds evasive or pretentious in one language/culture might be normal politeness or standard professional register in another.
Need for Deep Expertise: Developing reliable detection requires more than translation; it needs input from linguists, anthropologists, and cultural experts to identify language-specific markers. Think of German "Schwafel" (waffle/drivel), Russian "пустословие" (pustoslovie - empty talk), or potentially unique rhetorical strategies in other languages. This is currently beyond our scope but a vital area for future exploration.
Culturally Specific Concepts: The relationship between language, truth, authority, and critique varies. Consider "blasphemy": it's a term deeply embedded in specific cultural/religious contexts. Is it itself bullshit? Is it a charge used to defend established (potentially bullshit) dogma? Or is it sometimes used by a speaker to critique what they perceive as bullshit (e.g., unquestionable religious claims)? Understanding these nuances is crucial to avoid crudely applying one culture's bullshit-detection lens to another. The goal is not to label cultural practices but to understand diverse ways language navigates (or avoids) truth and meaning.
Call for Collaboration: We actively seek partners with expertise in diverse languages and cultures to explore this properly.
10. Caveats Emptor: How Not To Wield This Thing
(Content largely unchanged from v0.2.2. Reiterate strongly:)
Judge Text, Not People/Jobs: Absolutely do not use Compass outputs to make assumptions or accusations about an author's job title, competence, or personal character based on Graeber's theories or anything else. Focus on the linguistic evidence presented in the text.
(Plus: Don't Automate Judgment, Avoid Cynicism Overload, Truth Defence, Tool Fallibility)
11. Why Bother? The Grand Motivation
(Content unchanged: Clarity, accountability, visibility, pushback against decay).
12. Speak Now: Request for Comments
With the Graeber context and cross-cultural challenges foregrounded:
Does framing Graeber as context rather than a detection target make sense? How else can we acknowledge potential systemic drivers?
Is the cross-cultural section appropriately ambitious yet cautious? What specific linguistic markers or cultural concepts related to bullshit should future research explore?
All previous questions still stand!
13. Bibliography: The Thinkers Behind the Madness
(Ensure Graeber (2018) is listed prominently alongside Frankfurt, Orwell, Wittgenstein, Grice, Kahneman, Ariely, Bergstrom/West, Bregman, Snyder, Parrish, Pennycook, Meyer, Peterson).
14. Contact Point
(Same as v0.2)
15. Legal Boilerplate
(Same as v0.2)

Okay, let's inject some XKCD/Wait But Why flavour, add Orwell, properly cite Wittgenstein, and generally make this RFC feel less like a dry specification and more like... well, something Rob Tyrie channeling those vibes might write.

Request for Comments: RFC FS02
(Replaces: Draft v0.1 White Paper)
Category: Experimental / Informational / Mildly Existential
Author: Rob Tyrie, Ironstone Advisory & Finger Spider Project (The guy wondering if this document scores high)
Date: April 1, 2025 (No joke, probably)
Title: The Bullshit Compass: Trying to Measure the Unmeasurable (Semantic Pattern Detection Framework v0.2)
(Inspired by the grand tradition of RFCs like 5321, 2616, and 742 - because if you're going to build something potentially world-breaking or utterly useless, you should at least write down how you think it works first.)
Status of this Memo
Look, this is basically throwing spaghetti at the wall to see what sticks, but in a structured, RFC-compliant way. It's about the "Bullshit Compass" – a tool trying (key word: trying) to sniff out language that sounds important but might just be... well, bullshit. We're putting this out there for people smarter than us (or just with different opinions, which is often the same thing) to poke holes in it. Go nuts. Distribution: Everywhere. Knock yourselves out.
Abstract
We're drowning in words. Some are useful, some are lies, and a whole lot fall into a murky category Frankfurt called "bullshit" – language crafted without caring if it's true, just that it sounds good, persuasive, or sufficiently jargon-filled. Think corporate mission statements, webinar hype, maybe even parts of this RFC. The Bullshit Compass is our attempt at a detector for this stuff. It mixes old-school linguistic pattern-spotting with new-fangled AI smarts (the non-sentient kind, we hope) to flag text that seems epistemically... shifty. It spits out scores and highlights weird bits, aiming to help people see through the fog. This RFC (FS02) lays out the grand plan, the moving parts, and why we think this isn't completely crazy.
Table of Contents
Introduction: So. Much. Bullshit. Why Tho?
Terminology: Defining Our Terms So We Sound Credible
The Bullshit Compass: How Does This Contraption Supposedly Work?
The Core Indicators: Our Bullshit Taxonomy (Now with More Orwell!) 4.1. Tautological Camouflage Rate (TCR): The "It Is What It Is" Index 4.2. Peterson Weakness Injector (PWI): Ideology Hiding in Plain Sight? 4.3. Semantic Drift Score (SDS): The "Wait, Weren't We Talking About Something Else?" Meter 4.4. Assertion Ambiguity Ratio (AAR): Measuring Strategic Waffling 4.5. Buzzword Load Index (BLI): How Much meaningless corporate speak can one document hold? 4.6. Pseudoscience Rhetoric Marker (PRM): Spotting Quantum Woo in Marketing Copy 4.7. Emotional Persuasion Flags (EPF): Detecting Appeals to Your Inner Lizard Brain 4.8. Orwellian Obfuscation Index (OOI): Language Designed to Prevent Thought
Context is King: Wittgenstein's Language Games Enter the Chat 5.1. Language Game Contextualization (LGC)
Enter the LLMs: Can AI Help Fight AI-Generated Waffle?
What It Spits Out & Who Might Actually Use This Thing 7.1. The Glorious Output 7.2. Potential Victims... Er, Users
How We're Building It & Giving It Away (Maybe) 8.1. The Current State of Affairs (Python & Prayers) 8.2. Where We Dream of Plugging It In 8.3. Giving Away the Code (Because Why Not?)
The Never-Ending To-Do List (Future Roadmap)
Important Caveats: How Not to Be Evil (or Stupid) With This Tool
So, What's The Point Again?
Okay, Smarty Pants, Your Turn: Request for Comments
Stuff We Read (References)
Who to Blame (Author's Address)
Legal Mumbo Jumbo (Copyright Notice)
1. Introduction: So. Much. Bullshit. Why Tho?
Ever read a corporate strategy doc and felt like you needed a translator, a philosopher, and a stiff drink? You're not alone. We're swimming in language designed not to communicate clearly, but to manage impressions. Frankfurt (1986) nailed it: it's not always lying, it's bullshit – talking without giving a damn about the truth. It's the native language of PowerPoint decks, synergy meetings, and LinkedIn thought leaders.
Why care? Because this stuff isn't harmless fluff:
Teams get high on their own supply of optimistic jargon, leading to terrible decisions.
Investors get dazzled by buzzwords and forget to ask if the emperor is wearing any clothes (or if the "disruptive paradigm shift" is just... a new button color).
Politicians (shocking, I know) use vague, feel-good language to avoid making actual commitments. Orwell wrote a whole essay about this (more on that later).
Your spell checker won't save you. Your grammar tool doesn't care if your sentence is profound or profoundly empty. We need something that looks deeper, something that asks, "Is there actually any there there?" We need semantic instrumentation. Hence, the Bullshit Compass. It's like a Geiger counter for empty rhetoric. (Disclaimer: May occasionally click ominously at perfectly reasonable sentences. Calibration required.)
2. Terminology: Defining Our Terms So We Sound Credible
Bullshit: See Frankfurt (1986). Language used like decorative garnish, not nutritious food. It cares about appearance, not truth-value.
Semantic Pattern Detection: Nerdy way of saying "looking for meaningful patterns in text," not just keywords. Like spotting that someone uses the word "innovative" 17 times but never explains what is new.
Epistemic Quality: Fancy term for "how much does this language actually care about knowledge, truth, and evidence?" Low quality = high bullshit potential.
Language Game: Hat tip to Wittgenstein (1953). Basically, words mean different things depending on the context or "game" being played. "Synergy" in a physics paper (weird, but maybe possible?) means something different than "synergy" in a marketing meeting (often means "we taped two things together and hope it works").
Orwellian Language: See Orwell (1946). Language that deliberately obscures meaning, often for political or bureaucratic ends. Think Newspeak, but subtler and sadly more common.
3. The Bullshit Compass: How Does This Contraption Supposedly Work?
We mashed together a few ideas:
Old-School RFC Vibes: Write down the plan before coding like mad. Makes you think (sometimes). Hence, RFC FS02.
Philosophers Knew Things: Frankfurt, Wittgenstein, Orwell... turns out they thought about language and truthiness quite a bit. We're borrowing heavily.
NLP & ML Magic: Computers are good at finding patterns. We're teaching them to find patterns that often correlate with bullshit.
At its heart, it's a scoring engine. It reads text, runs it through a battery of tests (see Section 4), and assigns scores. Think of it like a car dashboard – you get warning lights for specific issues (too much jargon, vague claims) and an overall "Check Engine Soon?" light (the composite Bullshit Score).
4. The Core Indicators: Our Bullshit Taxonomy (Now with More Orwell!)
This is where the magic (or educated guesswork) happens. We're currently looking for eight main types of linguistic shenanigans, plus a context check (Section 5).
4.1. Tautological Camouflage Rate (TCR): The "It Is What It Is" Index
Scores how often text says things that are true by definition but add zero information. "Our successful strategy led to success!" Thanks, Captain Obvious.
4.2. Peterson Weakness Injector (PWI): Ideology Hiding in Plain Sight?
Still workshopping the name, maybe "Ideological Freeloading Score"? Tries to spot when seemingly reasonable statements are used as cover to sneak in unrelated, often charged, claims without justifying them.
4.3. Semantic Drift Score (SDS): The "Wait, Weren't We Talking About Something Else?" Meter
Measures if the text wanders off-topic like your grandpa after Thanksgiving dinner. Sometimes it's just bad writing, sometimes it's deliberate misdirection.
4.4. Assertion Ambiguity Ratio (AAR): Measuring Strategic Waffling
How much hedging, vagueness, and "weasel words" are present? "We might potentially see some improvement in certain areas." High scores mean the author is allergic to making a concrete claim.
4.5. Buzzword Load Index (BLI): How Much Meaningless Corporate Speak Can One Document Hold?
Counts jargon, acronyms, and buzzwords, especially those used without definition or context. High scores suggest that someone swallowed a marketing dictionary. Think "leveraging synergistic paradigms." Shudder.
4.6. Pseudoscience Rhetoric Marker (PRM): Spotting Quantum Woo in Marketing Copy
Flags language borrows scientific terms ("quantum," "energy field," "resonance") but uses them metaphorically or nonsensically, especially common in wellness and self-help contexts trying to sound sciency.
4.7. Emotional Persuasion Flags (EPF): Detecting Appeals to Your Inner Lizard Brain
Looks for language designed to bypass your thinking brain and hit you right in the feels – tribalism ("us vs. them"), outrage-baiting, excessive flattery, fear-mongering.
4.8. Orwellian Obfuscation Index (OOI): Language Designed to Prevent Thought
(New! Thanks, George!) This indicator specifically targets the kind of linguistic sludge Orwell warned about in "Politics and the English Language" (1946). It looks for:
* Dying Metaphors: Clichés used so often they've lost all imagery ("level playing field," "think outside the box").
* Verbal False Limbs/Operators: Padding simple verbs with extra words to sound official ("make contact with" instead of "contact," "render inoperative" instead of "stop").
* Pretentious Diction: Using complex words ("utilize," "ameliorate," "initiate") where simple ones would do, often to make vague ideas seem profound.
* Meaningless Words: Politically charged or trendy words used so broadly they mean almost nothing ("digital transformation," "sustainability," "freedom," "accountability" - often used without specific examples).
Basically, language that makes lies sound truthful and murder respectable, or at least makes boring bureaucracy sound important.
5. Context is King: Wittgenstein's Language Games Enter the Chat
As Wittgenstein might say (if he used internet slang), using "disrupt" in a tech startup pitch is playing a different language game than using it in a report about earthquake preparedness. The Compass needs to know the difference, or it'll flag satire as serious bullshit and serious science as jargon.
5.1. Language Game Contextualization (LGC)
Our attempt to give the Compass this context-awareness. It asks: "Is this kind of language normal and expected here?" It compares the text's patterns to what's typical for the genre (report, email, poem, marketing fluff). This should help reduce embarrassing false alarms. We're looking at stuff like the "Measuring Bullshit in Language Games Played by ChatGPT" paper for inspiration on how to model this contrastively.
6. Enter the LLMs: Can AI Help Fight AI-Generated Waffle?
Oh, the irony. Since LLMs are getting really good at generating plausible-sounding bullshit, we're enlisting them (carefully!) to help detect it.
Spotting New Jargon: LLMs can help keep the buzzword dictionary up-to-date.
Satire vs. Scam: Using prompts to ask an LLM "Does this feel like satire, or is it trying to sell me crypto?" (Results may vary. Use with caution.)
Compare & Contrast: Feed it two documents on the same topic – one legit, one scammy – and ask the LLM to spot the rhetorical differences.
Finding Copy-Pasta: Spotting when the same fancy-sounding bullshit phrases get reused across dozens of corporate reports ("Epistemic fingerprinting").
LLMs are part of the  core to the v0.88 engine but can be optionally integrated via API calls for:
Dynamic Vocabulary: Updating BLI/OOI dictionaries with emerging jargon or euphemisms.
Enhanced LGC: Providing secondary input for genre classification.
Zero-Shot Flagging: Experimentally prompting LLMs to flag novel or subtle forms of bullshit not caught by existing indicators (use with extreme caution).
Coversational LLMs or CLMS will be applied - Convesatin has structure and when it break dowm or a speaker cose in to charismatic modse - bullshit =r may com soon after. 
Ironically, as conversational AI gets smoother, it also gets better at smooth-talking its way around issues. We're exploring ways to analyze these interactions, sometimes using other AI tools, to spot the digital equivalent of dodging the question.
Confabularum Ergo Sumus: Interpreted as "We converse, therefore we are," highlighting that if conversation defines the AI's function, then CLMs offer the technical means to analyze and detect bullshit within that core interaction.
Spotting the Script: Analyzing response patterns to detect when a chatbot drops the conversational thread and falls back into repetitive, canned answers, revealing the limits of its dynamic interaction.
Evasion Detection: Training models or using specific prompts to flag when a conversational AI consistently avoids direct questions, deflects sensitive inquiries, or provides overly vague, non-committal replies.
Hallucination Hunting: Employing cross-referencing against knowledge bases or internal consistency checks within the dialogue to pinpoint moments where the AI confidently asserts plausible-sounding but factually incorrect information.
Persona Policing: Identifying inconsistencies in the AI's presented persona, claimed knowledge, capabilities, or even memory within a single conversation ("Wait, didn't you just say the opposite?").
Context Collapse Check: Evaluating if the AI successfully maintains conversational context over longer exchanges or if it frequently "forgets" earlier parts of the discussion or disregards user instructions.
These conversational analysis techniques are being explored for integration, potentially via APIs, for:
Real-time Quality Flags: Alerting users or developers to potentially evasive or nonsensical responses during interaction.
Automated Log Auditing: Systematically reviewing chat histories for recurring conversational failures or patterns of misinformation.
Interaction Flow Analysis: Understanding where conversations typically break down or where users encounter frustrating interaction loops.
7. What It Spits Out & Who Might Actually Use This Thing
7.1. The Glorious Output
When you feed the Compass some text, it should give you back:
The Big Score: A single number (0-100, maybe?) for "Overall Bullshit Level." Handle with care.
Radar Chart of Doom: A cool-looking spiderweb chart showing how the text scored on each indicator (TCR, PWI, SDS, AAR, BLI, PRM, EPF, OOI, maybe LGC). Pin it on your wall!
Marked-Up Text: Your original text, but with questionable bits highlighted like a teacher grading a paper.
Rewrite Helper (Maybe?): Tentative suggestions for how to phrase things more clearly / less bullshit-ly. Use at your own risk. Might make your corporate comms too understandable.
7.2. Potential Victims... Er, Users
Who might want this?
Academics/Researchers: Checking if papers are inflated or just dense.
Investors/Analysts: Due diligence on that startup promising to "revolutionize the paradigm."
Managers/Execs: A check against internal echo chambers and overly optimistic reports. ("Does this marketing plan actually say anything?")
Anyone Wrangling AI Content: Is the AI writing poetry or just very convincing nonsense?
Journalists/Fact-Checkers: An extra tool to spot rhetorical tricks, not just factual errors.
8. How We're Building It & Giving It Away (Maybe)
8.1. The Current State of Affairs (Python & Prayers)
Right now, it's a bunch of Python scripts. You can run it from the command line. It probably crashes sometimes. It has settings for how much detail it spits out.
8.2. Where We Dream of Plugging It In
Wouldn't it be cool if this was just... everywhere?
Red flag emails before you get sucked into a pointless thread? (Outlook plugin)
Highlight waffle in shared docs? (Google Docs, SharePoint add-on)
Analyze web pages on the fly? (Browser plugin)
Maybe even a GitHub repo where the community can argue about the spec via RFC-style pull requests? Meta!
8.3. Giving Away the Code (Because Why Not?)
Plan is to make it open source (MIT license, probably). Let the community play with it, break it, improve it. What could possibly go wrong?
9. The Never-Ending To-Do List (Future Roadmap)
Oh, we're just getting started.
Let LLMs do more of the heavy lifting on scoring (carefully!).
Make it work in languages other than English (because bullshit is universal).
Train it specifically to tell high-effort satire from low-effort grift.
Real-time analysis for meetings/chat? (Terrifying privacy implications. Needs thought.)
Integrate with the bigger "Finger Spider" platform for tracking bullshit across all an organization's documents (even more terrifying).
Maybe a "Trust Index" thing? (That's RFC FS03 territory).
10. Important Caveats: How Not to Be Evil (or Stupid) With This Tool
Okay, serious talk for a second. This tool could be misused. Badly.
Don't Be a Jerk: Don't just point at a score and say "See! Bullshit!" Use it as a starting point for thinking, not a shortcut to dismiss ideas you don't like. It should encourage critical reading, not replace it.
It Will Be Wrong Sometimes: False positives (flagging good text) and false negatives (missing bad text) WILL happen. Especially with clever or unusual language. Don't treat the score as gospel. It's a probability estimate, not a magic truth detector.
People Will Game It: Once people know what it looks for, they'll write around it. This is an arms race, folks.
Bias is Real: The data we train this on could have biases. It might unfairly flag certain writing styles. We need to be vigilant about this.
Clarity, Not Censorship: The goal here is to encourage clearer, more honest communication. It absolutely should not be used to shut down legitimate dissent, enforce stylistic conformity, or punish people for not writing like a robot. If it starts feeling like that, we've failed.
Think of it like a spell checker. Useful, but sometimes flags your perfectly valid name as a typo, and doesn't understand poetry at all. Use your judgment.
11. So, What's The Point Again?
To hold language accountable. To make the invisible structures of rhetoric visible. To give people a tool to push back against the tide of empty jargon and persuasive manipulation. It's not about being anti-business or anti-politics; it's about being pro-clarity and pro-honesty. We think that's worth a shot. It's an epistemological tool, not an adversarial one. (Okay, maybe a little adversarial towards deliberate obfuscation.)
12. Okay, Smarty Pants, Your Turn: Request for Comments
Seriously, tell us what you think. Rip it apart (constructively, ideally).
Does the whole concept make sense? Is it doomed?
Are the indicators sensible? Missing any big ones? Is the Orwell one useful? Is "PWI" a terrible name? (Yes, probably.)
How should the scoring actually work?
How can we make the context (LGC) part smarter?
How do we avoid the pitfalls in Section 10?
Got better ideas? Lay 'em on us.
Send feedback to the author below. Or yell into the void. Your choice.
13. Stuff We Read (References)
13. Foundational Bibliography & References
This list includes works cited or influential in the development of the Bullshit Compass framework (v0.88).
Ariely, D. (2008). Predictably irrational: The hidden forces that shape our decisions. HarperCollins.
Bergstrom, C. T., & West, J. D. (2020). Calling bullshit: The art of skepticism in a data-driven world. Random House.
Bregman, R. (2019). Humankind: A hopeful history. Little, Brown and Company.
Cerf, V. G. (Ed.). (1975). RFC 742: Finger protocol. RFC Editor. https://www.rfc-editor.org/info/rfc742
Fielding, R., Gettys, J., Mogul, J., Frystyk, H., Masinter, L., Leach, P., & Berners-Lee, T. (1999). RFC 2616: Hypertext Transfer Protocol -- HTTP/1.1. RFC Editor. https://www.rfc-editor.org/info/rfc2616 (Note: Obsoleted by RFCs 7230-7235, cited for historical context)
Frankfurt, H. G. (1986). On bullshit. Raritan Quarterly Review, 6(2). (Reprinted as: Frankfurt, H. G. (2005). On bullshit. Princeton University Press.)
Graeber, D. (2018). Bullshit jobs: A theory. Simon & Schuster.
Grice, H. P. (1975). Logic and conversation. In P. Cole & J. L. Morgan (Eds.), Syntax and semantics, Vol. 3: Speech acts (pp. 41–58). Academic Press.
Kahneman, D. (2011). Thinking, fast and slow. Farrar, Straus and Giroux.
Klensin, J. C. (Ed.). (2008). RFC 5321: Simple Mail Transfer Protocol. RFC Editor. https://www.rfc-editor.org/info/rfc5321
Meyer, P. (2010). Liespotting: Proven techniques to detect deception. St. Martin's Press.
Orwell, G. (1946, April). Politics and the English language. Horizon.
Parrish, S. (Host). (n.d.). Farnam Street Blog & The Knowledge Project Podcast. Farnam Street Media Inc. Retrieved April 1, 2025, from https://fs.blog/ (General influence cited)
Pennycook, A. (2001). Critical applied linguistics: A critical introduction. Lawrence Erlbaum Associates.
Peterson, J. B. (1999). Maps of meaning: The architecture of belief. Routledge. (Cited as influence)
Peterson, J. B. (2018). 12 rules for life: An antidote to chaos. Random House Canada. (Cited as influence)
Snyder, T. (2017). On tyranny: Twenty lessons from the twentieth century. Tim Duggan Books.
Wittgenstein, L. (1953). Philosophical Investigations (G. E. M. Anscombe, Trans.). Blackwell Publishing.

14. Who to Blame (Author's Address)
Rob Tyrie
Ironstone Advisory & Finger Spider Project
Email: rob@ironstoneadvisory,com
Website: [Working Title fingerspider.com or ironstone.net?]
15. Legal Mumbo Jumbo (Copyright Notice)
Copyright (c) 2025 Rob Tyrie / Ironstone Advisory / Finger Spider Project. Do what you want with this text (copy, share, translate, make fun of it), just keep this notice and the author's name attached. Don't modify this document itself in weird ways (like removing this notice). We're giving this away hoping it's useful, but it comes "AS IS" - no warranties, promises, or guarantees it won't accidentally classify Shakespeare as bullshit. Use your brain.
